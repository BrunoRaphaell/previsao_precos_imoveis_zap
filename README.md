
# Regress√£o: Prevendo o pre√ßo de im√≥veis do Rio de Janeiro

R√°pida descri√ß√£o do objetivo de fazer esse projeto

| :placard: Vitrine.Dev |     |
| -------------  | --- |
| :sparkles: Nome        | **Prevendo o pre√ßo de im√≥veis do Rio de Janeiro**
| :label: Tecnologias | Python, scikit-learn, Seaborn, Jupyter Notebook
| :rocket: URL         | -
| :fire: Desafio     | -

<!-- Inserir imagem com a #vitrinedev ao final do link -->
![](https://invexo.com.br/blog/wp-content/uploads/2020/08/viver-no-rio-de-janeiro-rj.jpg)

## Detalhes do projeto

<p>
   <img src="http://img.shields.io/static/v1?label=STATUS&message=EM%20DESENVOLVIMENTO&color=RED&style=for-the-badge"/>
</p>



### üìù Resumo

O projeto consistiu em tratar uma base de dados retirado do site **[zap im√≥veis](https://www.zapimoveis.com.br/?gclid=CjwKCAjwkMeUBhBuEiwA4hpqEJ-zRtqOKwUjCjzkYA3a1SgjxB6nhAlN_WlG9Q028cVeNAInIH_EuRoCyTgQAvD_BwE&utm_referrer=https%3A%2F%2Fwww.google.com%2F)** referente a im√≥veis do Rio de Janeiro, construir an√°lises gr√°ficas para entendimento dessa base, desenvolver e avaliar modelos de regress√£o capazes de prever o pre√ßo de im√≥veis.

### üíª Organiza√ß√£o do projeto
------------

    ‚îú‚îÄ‚îÄ LICENSE
    ‚îú‚îÄ‚îÄ Makefile           <- Makefile com comandos como `make data` ou `make train`.
    ‚îú‚îÄ‚îÄ README.md          <- Informa√ß√µes sobre o projeto.
    ‚îú‚îÄ‚îÄ data
    ‚îÇ   ‚îú‚îÄ‚îÄ external       <- Dados de fontes de terceiros..
    ‚îÇ   ‚îú‚îÄ‚îÄ interim        <- Dados intermedi√°rios que foram transformados.
    ‚îÇ   ‚îú‚îÄ‚îÄ processed      <- Dados finais para modelagem.
    ‚îÇ   ‚îî‚îÄ‚îÄ raw            <- Dados originais, imut√°veis.
    ‚îÇ
    ‚îú‚îÄ‚îÄ docs               <- Um projeto Sphinx padr√£o; veja sphinx-doc.org para detalhes.
    ‚îÇ
    ‚îú‚îÄ‚îÄ models             <- Modelos treinados e serializados, previs√µes de modelos ou resumos de modelos.
    ‚îÇ
    ‚îú‚îÄ‚îÄ notebooks          <- Notebooks Jupyter.
    ‚îÇ
    ‚îú‚îÄ‚îÄ references         <- Dicion√°rios de dados, manuais e todos os outros materiais explicativos..
    ‚îÇ
    ‚îú‚îÄ‚îÄ reports            <- An√°lise gerada como HTML, PDF, LaTeX, etc.
    ‚îÇ   ‚îî‚îÄ‚îÄ figures        <- Gr√°ficos e figuras gerados para serem usados em relat√≥rios
    ‚îÇ
    ‚îú‚îÄ‚îÄ requirements.txt   <- O arquivo de requisitos para reproduzir o ambiente de an√°lise, por exemplo,
    ‚îÇ                         gerado com `pip freeze > requirements.txt`
    ‚îÇ
    ‚îú‚îÄ‚îÄ setup.py           <- Torna o projeto pip instal√°vel (pip install -e .) para que o src possa ser importado
    ‚îú‚îÄ‚îÄ src                <- C√≥digo fonte para uso neste projeto.
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py    <- Torna src um m√≥dulo Python
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ data           <- Scripts para baixar ou gerar dados
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ make_dataset.py
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ features       <- Scripts para transformar dados brutos em recursos para modelagem
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ build_features.py
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ models         <- Scripts para treinar modelos e, em seguida, usar modelos treinados para fazer
    ‚îÇ   ‚îÇ   ‚îÇ                 predi√ß√µes
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predict_model.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_model.py
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ visualization  <- Scripts para criar visualiza√ß√µes explorat√≥rias e orientadas a resultados
    ‚îÇ       ‚îî‚îÄ‚îÄ visualize.py
    ‚îÇ
    ‚îî‚îÄ‚îÄ tox.ini            <- arquivo tox com configura√ß√µes para execu√ß√£o de tox; veja tox.readthedocs.io


<p><small>Projeto baseado no <a target="_blank" href="https://drivendata.github.io/cookiecutter-data-science/">template para data scince de cookiecutter</a>.</small></p>

--------
#### üîß Instala√ß√£o das bibliotecas

Para o desenvolvimento do projeto, foram utilizadas bibliotecas como **[pandas](https://pandas.pydata.org/)**, **[matplotlib](https://matplotlib.org/)**, **[scikit-learn](https://scikit-learn.org/)**,  **[seaborn](https://seaborn.pydata.org/)** e **[yellowbrick](https://www.scikit-yb.org/en/latest/)**.

Para instalar das bibliotecas utilizadas no projeto √© necess√°rio utilizar o comando **pip install** em uma c√©lula do notebook ou no terminal (caso execute no terminal, excluir o ponto de exclama√ß√£o do comando).

```
!pip install pandas
!pip install seaborn
!pip install matplotlib
!pip install scikit-learn
```

<h3>Base de dados inicial</h3>

A base de dados inicial, antes de ser tratada no primeiro [notebook](https://github.com/BrunoRaphaell/previsao_precos_imoveis_zap/blob/master/notebooks/1_Limpando%20a%20base%20de%20dados.ipynb), encontra-se dispon√≠vel nesse [link](https://drive.google.com/file/d/1av_5fuOYTW95esDRypeAwo4yIBavh2CW/view?usp=sharing). Devido ao seu tamanho n√£o foi poss√≠vel realizar o upload da base de dados para o GitHub.

<h3>üìì Notebooks:</h3>

<h4><a href='https://github.com/BrunoRaphaell/previsao_precos_imoveis_zap/blob/master/notebooks/1_Limpando%20a%20base%20de%20dados.ipynb'>1: Limpando a base de dados</a></h4>

Esse primeiro notebook consistiu em realizar o tratamento do JSON bruto com os dados do zap im√≥veis. Para esse tratamento foram explorados diversos m√©todos da biblioteca pandas para tratamento de JSONs. Ao final do tratamento foi gerado um arquivo CSV com os dados que ser√£o utilizados no segundo notebook. Esses dados est√£o dispon√≠veis nesse [link](https://raw.githubusercontent.com/BrunoRaphaell/previsao_precos_imoveis_zap/master/dados/dados_tratados.csv).

<h5><a href='https://github.com/BrunoRaphaell/previsao_precos_imoveis_zap/blob/master/references/dic_dados.txt'>Dicion√°rio dos dados:</a></h5>

`usableAreas`: √Årea utiliz√°vel do im√≥vel. √Årea constru√≠da

`totalAreas`: √Årea total do im√≥vel. 

`bedrooms`: Quantidade de quartos.

`bathrooms`: Quantidade de banheiros.

`parkingSpaces`: Quantidade de vagas de estacionamento.

`suites`: Quantidade de su√≠tes.

`longitude`: Longitude do im√≥vel.

`latitude`: Latitude do im√≥vel.

`yearlyIptu`: Valor do IPTU anual.

`monthlyCondoFee`: Valor da taxa condominial mensal.

`price`: Pre√ßo do im√≥vel. **Vari√°vel target**

<h4><a href='https://github.com/BrunoRaphaell/previsao_precos_imoveis_zap/blob/master/notebooks/2_Visualizando%20e%20tratando%20os%20dados.ipynb'>2: Visualizando e tratando os dados</a></h4>

O segundo notebook consistiu em visualizar os dados da base de dados e tratar os dados para que fossem mais adequados para o desenvolvimento do modelo de regress√£o.

<h5>Visualiza√ß√µes vari√°veis num√©ricas:</h5>

* Histograma:

<center><img src="https://i.imgur.com/oIElmvs.png"></center>

Analisando a distribui√ß√£o da vari√°vel target percebemos que √© uma curva assim√©trica √† direita. Estatisticamente temos:

$$Moda < Mediana < m√©dia$$

* Boxplot:

<center><img src="https://i.imgur.com/T8ThCdt.png"></center>

Percebe-se que o boxplot segue a mesma l√≥gica que o histograma, por√©m aqui fica mais evidente a presen√ßa de amostras candidatas a outliers.,

Analisando a distribui√ß√£o do pre√ßo por zona:

<center><img src="https://i.imgur.com/sxXFqtA.png"></center>

Analisando a distribui√ß√£o dos pre√ßos dos im√≥veis por tipo do im√≥vel:

<center><img src="https://i.imgur.com/mKpJXTw.png"></center>

<h4>Visualiza√ß√µes vari√°veis categ√≥ricas:</h4>

* Barplot: 

<center><img src="https://i.imgur.com/QVdt79D.png"></center>

Percebe-se que h√° muito mais im√≥veis de apartamentos para serem vendidos do que qualquer outro tipo. Analisando o pre√ßo m√©dio por tipo do im√≥vel: 

<center><img src="https://i.imgur.com/JP5TOVy.png"></center>

Quantidade de im√≥veis por zona:

<center><img src="https://i.imgur.com/YkLTwWZ.png"></center>

Pre√ßo m√©dio por zona do im√≥vel:

<center><img src="https://i.imgur.com/9yGKEOr.png"></center>

Pelas imagens acima percebe-se que h√° uma maior quantidade de im√≥veis da zona oeste do Rio de Janeiro, por√©m os im√≥veis mais caros est√£o na zona sul. O que faz total sentido pois de acordo com o artigo "[Conhe√ßa 13 bairros nobres do RJ e o que tem de mais legal em cada um](https://blog.loft.com.br/bairros-nobres-do-rj/)": 

> N√£o √© √† toa que cinco dos bairros mais caros do pa√≠s est√£o localizados na Zona Sul carioca, sendo eles o Leblon, Ipanema, Lagoa, G√°vea e Jardim Bot√¢nico.

<h5>Correla√ß√£o:</h5>

<center><img src="https://i.imgur.com/mqdnxUs.png"></center>

N√£o h√° vari√°veis com alta correla√ß√£o entre si, logo n√£o haver√° problemas de multicolinearidade.

<h5>Rela√ß√£o das vari√°veis com a vari√°vel target:</h5>

<center><img src="https://i.imgur.com/p5PZeaF.png"></center>

Ap√≥s a transforma√ß√£o logar√≠tmica:

<center><img src="https://i.imgur.com/GKlCLDI.png"></center>
<center><img src="https://i.imgur.com/1nAXqYj.png"></center>

Ap√≥s a constru√ß√£o das visualiza√ß√µes e transforma√ß√£o logar√≠tmica foi transformou-se as vari√°veis categ√≥ricas em dummies e salvou em um novo arquivo CSV, chamado "[dados_OneHotEncoder.csv](https://raw.githubusercontent.com/BrunoRaphaell/previsao_precos_imoveis_zap/master/data/processed/dados_OneHotEncoder.csv)"

<h4><a href='https://github.com/BrunoRaphaell/previsao_precos_imoveis_zap/blob/master/notebooks/3_criando%20e%20testando%20modelos%20de%20ml.ipynb'>3: criando e testando modelos de ml</a></h5>

O terceiro notebook consistiu em criar e testar os modelos de regress√£o. Foram escolhidos os seguintes modelos:

* [Linear Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)
* [DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)
* [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)
* [GradientBoostingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html)

A primeira parte consistiu em testar os modelos e escolher o que apresentasse melhor desempenho com as m√©tricas `MSE`, `RMSE`, `MAE` e `R2` e ent√£o realizar o tunning dos hiperpar√¢metros e obter um modelo ainda melhor. Abaixo est√° um resumo dos resultados obtidos:

![](https://i.imgur.com/Kmqv7Dp.png)

O modelo escolhido foi [GradientBoostingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html) e para realizar o tunning dos hyperparametros foi utilizado o [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) e os melhores par√¢metros foram obtendo um `mean_test_score` de 0.902027:

```
{'learning_rate': 0.1,
 'max_depth': 8,
 'min_samples_split': 4,
 'n_estimators': 200}
```

<h3>üí≠ Continua√ß√£o com mlflow</h3>

Para continuar com o desenvolvimento do projeto, foi utilizado o [mlflow](https://mlflow.org/), que est√° dispon√≠vel nesse outro reposit√≥rio "[mlflow_previsao_precos_imoveis_zap](https://github.com/BrunoRaphaell/mlflow_previsao_precos_imoveis_zap)". 

<h3>üßëüèº Autor</h3>

[<img src="https://avatars.githubusercontent.com/u/24321228?v=4" width=115><br><sub>Bruno Raphaell</sub>](https://www.linkedin.com/in/bruno-raphaell-alves-de-matos/) 


